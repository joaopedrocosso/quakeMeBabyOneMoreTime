{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53460ae1-6847-48e8-b5a3-7f3105a4ebd8",
   "metadata": {},
   "source": [
    "# Library Import\n",
    "This section imports all the necessary libraries required for data processing, feature extraction, and cloud interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70fa4b5-ad13-4199-9d64-f8e95b30423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from obspy import read\n",
    "from utils.feature_extraction_mars import *\n",
    "from timeit import default_timer as timer\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import os\n",
    "# from google.cloud import storage # Uncomment this line if you want to use Cloud Storage to upload the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "763deaff-058c-403f-bfeb-b77012fab6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'XB.ELYSE.02.BHV.2019-07-26HR12_evid0033', 'XB.ELYSE.02.BHV.2019-05-23HR02_evid0041', 'XB.ELYSE.02.BHV.2022-05-04HR23_evid0001', 'XB.ELYSE.02.BHV.2022-04-09HR22_evid0002', 'XB.ELYSE.02.BHV.2019-09-21HR03_evid0032', 'XB.ELYSE.02.BHV.2021-12-24HR22_evid0007', 'XB.ELYSE.02.BHV.2021-10-11HR23_evid0011', 'XB.ELYSE.02.BHV.2021-05-02HR01_evid0017', 'XB.ELYSE.02.BHV.2019-07-26HR12_evid0034'}\n"
     ]
    }
   ],
   "source": [
    "folder_path = './data/mars/test/data'\n",
    "files = {os.path.splitext(f)[0] for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))}\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d96ac1-de28-4381-b268-a14c96c22a7d",
   "metadata": {},
   "source": [
    "# Function for Processing Events (CSV and mseed)\n",
    "- All data from the CSV files and the statuses from the mseed files are being extracted.\n",
    "- **Additionally, we have a utility file for creating new event features using mathematical equations with the Scipy library; all these new features are utilized in training the neural network.**\n",
    "\n",
    "## Each row represents an event from the lunar dataset. For each event:\n",
    "- CSV data is loaded and processed. **We are adding the filename to the dataframe**.\n",
    "- Data from mseed files (including network and station status) is extracted.\n",
    "- The CSV and mseed data are combined and returned as a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201dc4c3-2484-43a7-a9e7-fa4dfd1a4248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Took 23.3906 seconds to process index 0\n",
      "1\n",
      "Took 22.3285 seconds to process index 1\n",
      "2\n",
      "Took 22.0801 seconds to process index 2\n",
      "3\n",
      "Took 22.1471 seconds to process index 3\n",
      "4\n",
      "Took 21.7625 seconds to process index 4\n",
      "5\n",
      "Took 21.5100 seconds to process index 5\n",
      "6\n",
      "Took 21.3077 seconds to process index 6\n",
      "7\n",
      "Took 21.5255 seconds to process index 7\n",
      "8\n",
      "Took 22.0616 seconds to process index 8\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty DataFrame to hold all concatenated data\n",
    "df_combined = pd.DataFrame()\n",
    "\n",
    "for index, filename in enumerate(files):\n",
    "    try:\n",
    "        print(index)\n",
    "        start = timer()\n",
    "        \n",
    "        data_directory = f'./data/mars/test/data/{filename}'\n",
    "        \n",
    "        # Read CSV data\n",
    "        df_data_csv = pd.read_csv(f\"{data_directory}.csv\", parse_dates=['time(%Y-%m-%dT%H:%M:%S.%f)'])\n",
    "        df_data_csv['filename']=filename\n",
    "    \n",
    "        # Concatenate features from mseed\n",
    "        mseed_file = f'{data_directory}.mseed'\n",
    "        st = read(mseed_file)\n",
    "        df_data_csv['network'] = st[0].stats['network']\n",
    "        df_data_csv['station'] = st[0].stats['station']\n",
    "        df_data_csv['location'] = st[0].stats['location']\n",
    "        df_data_csv['channel'] = st[0].stats['channel']\n",
    "        df_data_csv['sampling_rate'] = st[0].stats['sampling_rate']\n",
    "        df_data_csv['delta'] = st[0].stats['delta']\n",
    "        df_data_csv['npts'] = st[0].stats['npts']\n",
    "        df_data_csv['calib'] = st[0].stats['calib']\n",
    "        \n",
    "        # Concatenando novas features\n",
    "        sampling_rate = st[0].stats['sampling_rate']\n",
    "        features = process_seismic_data(df_data_csv, sampling_rate)\n",
    "        df_data_csv['mean_velocity']= features['mean_velocity']\n",
    "        df_data_csv['std_velocity']= features['std_velocity']\n",
    "        df_data_csv['max_velocity']= features['max_velocity']\n",
    "        df_data_csv['min_velocity']= features['min_velocity']\n",
    "        df_data_csv['total_energy']= features['total_energy']\n",
    "        df_data_csv['rms_value']= features['rms_value']\n",
    "        df_data_csv['peak_count']= features['peak_count']\n",
    "        df_data_csv['valley_count']= features['valley_count']\n",
    "        df_data_csv['fft_values']= features['fft_values']\n",
    "        df_data_csv['fft_freqs']= features['fft_freqs']\n",
    "        df_data_csv['autocorrelation']= features['autocorrelation']\n",
    "        df_data_csv['acceleration']= features['acceleration']\n",
    "        df_data_csv['jerk']= features['jerk']\n",
    "        df_data_csv['cumulative_energy']= features['cumulative_energy']\n",
    "    \n",
    "        # Concatenate df_data_csv to the main DataFrame\n",
    "        df_combined = pd.concat([df_combined, df_data_csv], ignore_index=True)\n",
    "        end = timer()  # Stop the timer\n",
    "        elapsed_time = end - start  # Calculate elapsed time\n",
    "        print(f\"Took {elapsed_time:.4f} seconds to process index {index}\",end='\\n')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92c45ea-32f8-434f-9adf-0c00bfd07fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time(%Y-%m-%dT%H:%M:%S.%f)</th>\n",
       "      <th>rel_time(sec)</th>\n",
       "      <th>velocity(c/s)</th>\n",
       "      <th>filename</th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>location</th>\n",
       "      <th>channel</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>delta</th>\n",
       "      <th>...</th>\n",
       "      <th>total_energy</th>\n",
       "      <th>rms_value</th>\n",
       "      <th>peak_count</th>\n",
       "      <th>valley_count</th>\n",
       "      <th>fft_values</th>\n",
       "      <th>fft_freqs</th>\n",
       "      <th>autocorrelation</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>jerk</th>\n",
       "      <th>cumulative_energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-07-26 12:00:00.010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>XB.ELYSE.02.BHV.2019-07-26HR12_evid0033</td>\n",
       "      <td>XB</td>\n",
       "      <td>ELYSE</td>\n",
       "      <td>02</td>\n",
       "      <td>BHV</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925330e+09</td>\n",
       "      <td>163.525816</td>\n",
       "      <td>21827</td>\n",
       "      <td>21826</td>\n",
       "      <td>-7.653055e+03-0.000000e+                    00j</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.925330e+09</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>-0.015385</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-07-26 12:00:00.060</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>XB.ELYSE.02.BHV.2019-07-26HR12_evid0033</td>\n",
       "      <td>XB</td>\n",
       "      <td>ELYSE</td>\n",
       "      <td>02</td>\n",
       "      <td>BHV</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925330e+09</td>\n",
       "      <td>163.525816</td>\n",
       "      <td>21827</td>\n",
       "      <td>21826</td>\n",
       "      <td>5.032086e+05+4.519214e+                    04j</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>1.877502e+09</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>-0.179246</td>\n",
       "      <td>1.117610e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-07-26 12:00:00.110</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>XB.ELYSE.02.BHV.2019-07-26HR12_evid0033</td>\n",
       "      <td>XB</td>\n",
       "      <td>ELYSE</td>\n",
       "      <td>02</td>\n",
       "      <td>BHV</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925330e+09</td>\n",
       "      <td>163.525816</td>\n",
       "      <td>21827</td>\n",
       "      <td>21826</td>\n",
       "      <td>-1.293472e+06-3.854668e+                    05j</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1.860496e+09</td>\n",
       "      <td>-0.016587</td>\n",
       "      <td>0.155938</td>\n",
       "      <td>3.041675e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-26 12:00:00.160</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>XB.ELYSE.02.BHV.2019-07-26HR12_evid0033</td>\n",
       "      <td>XB</td>\n",
       "      <td>ELYSE</td>\n",
       "      <td>02</td>\n",
       "      <td>BHV</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925330e+09</td>\n",
       "      <td>163.525816</td>\n",
       "      <td>21827</td>\n",
       "      <td>21826</td>\n",
       "      <td>-7.829146e+05+4.120607e+                    05j</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>1.875679e+09</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.657648</td>\n",
       "      <td>6.373614e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-26 12:00:00.210</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>XB.ELYSE.02.BHV.2019-07-26HR12_evid0033</td>\n",
       "      <td>XB</td>\n",
       "      <td>ELYSE</td>\n",
       "      <td>02</td>\n",
       "      <td>BHV</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.925330e+09</td>\n",
       "      <td>163.525816</td>\n",
       "      <td>21827</td>\n",
       "      <td>21826</td>\n",
       "      <td>1.182444e+06+8.483111e+                    05j</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>1.848085e+09</td>\n",
       "      <td>0.049177</td>\n",
       "      <td>-0.520651</td>\n",
       "      <td>1.970583e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  time(%Y-%m-%dT%H:%M:%S.%f)  rel_time(sec)  velocity(c/s)  \\\n",
       "0    2019-07-26 12:00:00.010           0.00       0.000000   \n",
       "1    2019-07-26 12:00:00.060           0.05       0.000067   \n",
       "2    2019-07-26 12:00:00.110           0.10       0.000057   \n",
       "3    2019-07-26 12:00:00.160           0.15      -0.001592   \n",
       "4    2019-07-26 12:00:00.210           0.20       0.001673   \n",
       "\n",
       "                                  filename network station location channel  \\\n",
       "0  XB.ELYSE.02.BHV.2019-07-26HR12_evid0033      XB   ELYSE       02     BHV   \n",
       "1  XB.ELYSE.02.BHV.2019-07-26HR12_evid0033      XB   ELYSE       02     BHV   \n",
       "2  XB.ELYSE.02.BHV.2019-07-26HR12_evid0033      XB   ELYSE       02     BHV   \n",
       "3  XB.ELYSE.02.BHV.2019-07-26HR12_evid0033      XB   ELYSE       02     BHV   \n",
       "4  XB.ELYSE.02.BHV.2019-07-26HR12_evid0033      XB   ELYSE       02     BHV   \n",
       "\n",
       "   sampling_rate  delta  ...  total_energy   rms_value  peak_count  \\\n",
       "0           20.0   0.05  ...  1.925330e+09  163.525816       21827   \n",
       "1           20.0   0.05  ...  1.925330e+09  163.525816       21827   \n",
       "2           20.0   0.05  ...  1.925330e+09  163.525816       21827   \n",
       "3           20.0   0.05  ...  1.925330e+09  163.525816       21827   \n",
       "4           20.0   0.05  ...  1.925330e+09  163.525816       21827   \n",
       "\n",
       "   valley_count                                      fft_values  fft_freqs  \\\n",
       "0         21826 -7.653055e+03-0.000000e+                    00j   0.000000   \n",
       "1         21826  5.032086e+05+4.519214e+                    04j   0.000278   \n",
       "2         21826 -1.293472e+06-3.854668e+                    05j   0.000556   \n",
       "3         21826 -7.829146e+05+4.120607e+                    05j   0.000833   \n",
       "4         21826  1.182444e+06+8.483111e+                    05j   0.001111   \n",
       "\n",
       "   autocorrelation  acceleration      jerk  cumulative_energy  \n",
       "0     1.925330e+09      0.001337 -0.015385       0.000000e+00  \n",
       "1     1.877502e+09      0.000568 -0.179246       1.117610e-10  \n",
       "2     1.860496e+09     -0.016587  0.155938       3.041675e-10  \n",
       "3     1.875679e+09      0.016162  0.657648       6.373614e-08  \n",
       "4     1.848085e+09      0.049177 -0.520651       1.970583e-07  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57df1d10-7670-4826-95c7-676a404427e3",
   "metadata": {},
   "source": [
    "# Saving the File Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b7e665-ac5f-4cee-9df7-e6512f128a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv(\"./test_mars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737d710-49ed-44e5-8f9b-45834091037e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
